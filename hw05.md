# Information（信息）
Information is any entity or form that provides the answer to a question of some kind or resolves uncertainty. It is thus related to data and knowledge, as data represents values attributed to parameters, and knowledge signifies understanding of real things or abstract concepts.[1] As it regards data, the information's existence is not necessarily coupled to an observer (it exists beyond an event horizon, for example), while in the case of knowledge, the information requires a cognitive observer. 
Information is conveyed either as the content of a message or through direct or indirect observation. That which is perceived can be construed as a message in its own right, and in that sense, information is always conveyed as the content of a message. 
Information can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a signal). It can also be encrypted for safe storage and communication. 
Information reduces uncertainty. The uncertainty of an event is measured by its probability of occurrence and is inversely proportional to that. The more uncertain an event, the more information is required to resolve uncertainty of that event. The bit is a typical unit of information, but other units such as the nat may be used. For example, the information encoded in one "fair" coin flip is log2(2/1) = 1 bit, and in two fair coin flips is log2(4/1) = 2 bits. 
The concept that information is the message has different meanings in different contexts.[2] Thus the concept of information becomes closely related to notions of constraint, communication, control, data, form, education, knowledge, meaning, understanding, mental stimuli, pattern, perception, representation, and entropy. 
信息，指音讯、消息、通讯系统传输和处理的对象，泛指人类社会传播的一切内容。人通过获得、识别自然界和社会的不同信息来区别不同事物，得以认识和改造世界。在一切通讯和控制系统中，信息是一种普遍联系的形式。1948年，数学家香农在题为“通讯的数学理论”的论文中指出：“信息是用来消除随机不定性的东西”。创建一切宇宙万物的最基本万能单位是信息。
# Positional notatior（位置计数法）
Positional notation or place-value notation is a method of representing or encoding numbers. Positional notation is distinguished from other notations (such as Roman numerals) for its use of the same symbol for the different orders of magnitude (for example, the "ones place", "tens place", "hundreds place"). This greatly simplified arithmetic, leading to the rapid spread of the notation across the world. 
With the use of a radix point (decimal point in base-10), the notation can be extended to include fractions and the numeric expansions of real numbers. 
The Babylonian numeral system, base-60, was the first positional system developed, and its influence is present today in the way time and angles are counted in tallies related to 60, like 60 minutes in an hour, 360 degrees in a circle. The Hindu–Arabic numeral system, base-10, is the most commonly used system in the world today for most calculations. The binary numeral system, base-2, is straightforwardly implemented in digital electronic circuitry and used by almost all computer systems and electronics for calculations and representations. 
位置计数法或位值记数法是一个代表或编码方法数。位置符号区别于其他符号（如罗马数字）对于不同的相同的符号，它的使用数量级（例如，“个位”、“十位”、“百位”）。这大大简化了算术，导致世界各地迅速蔓延的符号。
在一个使用小数点（在十进制小数点），符号可以扩展到包括片段和数字扩展实数。
这个巴比伦数字系统，base-60，是第一个定位系统的发展，其影响也在今天的时间和角度提出计算与60吻合，像一小时60分钟，一圈360度。这个印度–阿拉伯数字系统，10，在世界上最常用的系统是大多数计算的今天。这个二进制，2直截了当地实施数字电子电路和几乎所有的计算机系统和电子计算和表示方法。
# Algorithm（流程图）
In mathematics and computer science, an algorithm (/ˈælɡərɪðəm/ ( listen)) is an unambiguous specification of how to solve a class of problems. Algorithms can perform calculation, data processing and automated reasoning tasks. 
As an effective method, an algorithm can be expressed within a finite amount of space and time[1] and in a well-defined formal language[2] for calculating a function.[3] Starting from an initial state and initial input (perhaps empty),[4] the instructions describe a computation that, when executed, proceeds through a finite[5] number of well-defined successive states, eventually producing "output"[6] and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.[7] 
The concept of algorithm has existed for centuries and the use of the concept can be ascribed to Greek mathematicians, e.g. the sieve of Eratosthenes and Euclid's algorithm;[8] the term algorithm itself derives from the 9th Century mathematician Muḥammad ibn Mūsā al'Khwārizmī, Latinized 'Algoritmi'. A partial formalization of what would become the modern notion of algorithm began with attempts to solve the Entscheidungsproblem (the "decision problem") posed by David Hilbert in 1928. Subsequent formalizations were framed as attempts to define "effective calculability"[9] or "effective method";[10] those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936–7 and 1939. 
流程图一个算法（Euclid的算法）的最大公约数（g.c.d.）两个数的计算一和B地点命名为A和B的算法进行连续减法两回路：如果测试B≥收益“是”（或真实的）（更准确数 B在位置B大于或等于数 一位置）然后，算法指定B←B−一（指数B−一替换旧的B）。同样，如果一个> B，然后←一−B.进程终止时（内容）B为0，得到g.c.d. A.（算法源于史葛2009:13；符号1977和Tausworthe绘画风格）。
进入数学和计算机科学, an算法(/ˈælɡərɪðəm/ ( 听)) is an unambiguous specification of how to solve a class of problems. Algorithms can perform计算，data processing和automated reasoning任务.
As aneffective method, an algorithm can be expressed within a finite amount of space and time[1]and in a well-defined formal language[2]for calculating a功能。[3]Starting from an initial state and initial input (perhaps空的),[4]the instructions describe a计算that, when执行, proceeds through a finite[5]number of well-defined successive states, eventually producing "output"[6]and terminating at a final ending state. The transition from one state to the next is not necessarilydeterministic; some algorithms, known asrandomized algorithms, incorporate random input.[7] 
The concept of算法has existed for centuries and the use of the concept can be ascribed to Greek mathematicians, e.g.埃拉托斯特尼筛法和Euclid的算法；[ 8 ]术语算法本身源于九世纪的数学家穆ḥammad IBN Mū的āal'khwā米ī“Algoritmi”，拉丁化。一部分的形式化将成为什么现代观念算法开始尝试去解决判定问题（“决策问题”）构成的希尔伯特1928。随后的形式化，被诬陷为试图定义“有效的可计算性“[ 9 ]或者“有效的方法”；[ 10 ]这些形式化，包括Gödel–埃尔布朗–克林 递归函数1930, 1934和1935，阿隆佐·邱奇的lambda演算1936，埃米尔·波斯特的配方11936，和艾伦·图灵的图灵机1936–7和1939。
# Software Bug（软件漏洞）
A software bug is an error, flaw, failure or fault in a computer program or system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. The process of fixing bugs is termed "debugging" and often uses formal techniques or tools to pinpoint bugs, and since the 1950s, some computer systems have been designed to also deter, detect or auto-correct various computer bugs during operations. 
Most bugs arise from mistakes and errors made in either a program's source code or its design, or in components and operating systems used by such programs. A few are caused by compilers producing incorrect code. A program that contains a large number of bugs, and/or bugs that seriously interfere with its functionality, is said to be buggy (defective). Bugs can trigger errors that may have ripple effects. Bugs may have subtle effects or cause the program to crash or freeze the computer. Other bugs qualify as security bugs and might, for example, enable a malicious user to bypass access controls in order to obtain unauthorized privileges. 
Some software bugs have been linked to disasters. Bugs in code that controls the Therac-25 radiation therapy machine were directly responsible for patient deaths in the 1980s. In 1996, the European Space Agency's US$1 billion prototype Ariane 5 rocket had to be destroyed less than a minute after launch due to a bug in the on-board guidance computer program. In June 1994, a Royal Air Force Chinook helicopter crashed into the Mull of Kintyre, killing 29. This was initially dismissed as pilot error, but an investigation by Computer Weekly convinced a House of Lords inquiry that it may have been caused by a software bug in the aircraft's engine-control computer.[1] 
In 2002, a study commissioned by the US Department of Commerce's National Institute of Standards and Technology concluded that "software bugs, or errors, are so prevalent and so detrimental that they cost the US economy an estimated $59 billion annually, or about 0.6 percent of the gross domestic product".[2] 
一个软件缺陷是一个错误，缺点，失败或过错在一个计算机程序或系统导致其产生错误或意外的结果，或是在意想不到的行为方式。修复漏洞的过程称为“调试“经常使用的正式的技术或工具来找出漏洞，并自上世纪50年代以来，一些计算机系统被设计用来防止，检测或自动纠正各种电脑错误操作时。
大多数错误引起的在任何一个程序的错误源代码或其设计，或在组件和操作系统通过这样的程序使用。几所造成的编译器产生错误的代码。一个程序，包含大量的错误，和/或错误，严重干扰了它的功能，可以说是婴儿车（缺陷）。错误可以触发，可能有错误涟漪效应。错误可能有微妙的影响或导致程序崩溃或冻结计算机。其他错误的资格安全漏洞可能，例如，使恶意用户绕过访问控制为了获得未经授权的权限。
一些软件错误都与灾害。错误代码控制Therac-25 放射治疗机直接负责在上世纪80年代，1996的病人死亡。欧洲航天局的1美元 亿原型 阿里安5火箭必须在船上指导计算机程序错误推出后不到一分钟了。1994年6月，英国皇家空军奇努克直升机坠毁进入琴泰岬，造成29。这是最初被认为是飞行员的失误，但调查计算机周刊相信一个上议院调查表明，它可能是通过飞机的一个软件缺陷造成的发动机控制电脑。[ 1 ] 
2002、委托美国研究商务部的美国国家标准与技术研究所得出的结论是：“软件错误或错误，是如此普遍，如此不利的，他们的成本估计为59美元的美国经济 亿美元，或约0.6%的国内生产总值”。
